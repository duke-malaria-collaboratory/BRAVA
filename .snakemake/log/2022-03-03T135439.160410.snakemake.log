Building DAG of jobs...
The code used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-code-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-code-changes)'.
The input used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-input-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-input-changes)'.
The params used to generate one or several output files has changed:
    To inspect which output files have changes, run 'snakemake --list-params-changes'.
    To trigger a re-run, use 'snakemake -R $(snakemake --list-params-changes)'.
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                       count    min threads    max threads
----------------------  -------  -------------  -------------
all                           1              1              1
call_haplotypes               1              1              1
clean_sequencing_reads        1              1              1
organize_folders              1              1              1
total                         4              1              1

Select jobs to execute...

[Thu Mar  3 13:54:41 2022]
rule clean_sequencing_reads:
    input: refs/AMA/AMA.fasta, raw_reads/1, raw_reads/2, adapters/forwardPrimers.fasta, adapters/reversePrimers.fasta
    output: out/fastq/AMA/1/*.fastq.gz, out/fastq/AMA/2/*.fastq.gz
    jobid: 1
    priority: 10
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
